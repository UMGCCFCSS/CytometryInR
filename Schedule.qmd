---
format: html
toc: TRUE
toc-location: right
toc-depth: 4
toc-expand: true
---
![](images/WebsiteBanner.png)

### Cytometry in R: A Course for Beginners

This is the tentative course schedule as of November 03, 2025. Please complete the [interest form](https://docs.google.com/forms/d/e/1FAIpQLScPK4V_WNSgQvZNq7aIHpoiX8pi3kiuCfI0Tp7hQkVJS3HPtQ/viewform?usp=publish-editor) to stay in the loop as we finalize date and times. If you would like us to cover additional topics, please suggest them to the emails in the interest form. Thanks! - David

<br>
<br>

### Workstation Setup

![](images/PopUpLab.jpeg){width=75%}

[**Week 1:**]{.underline} During this first session, we will ensure that everyone's computer gets properly setup, as well as start building individual participants familiarity with the software infrastructure that they will be using throughout the rest of the course. Namely, you will need to install [R](https://cran.rstudio.com/), [Rtools](https://cran.r-project.org/bin/windows/Rtools/), [Positron](https://positron.posit.co/), [Quarto](https://quarto.org/), and [Git](https://git-scm.com/); as well as setup and link to a [GitHub](https://github.com/) account. This session also touches on concepts behind version control and how to install R package from the various repositories ([CRAN](https://cran.r-project.org/), [Bioconductor](https://www.bioconductor.org/), [GitHub](https://github.com/r-lib/remotes)).

<br>
<br>

### File Paths

![](https://www.medschool.umaryland.edu/media/som/offices-of-the-dean/information-services/screenshots/mappedrives02.png)

[**Week 2:**]{.underline} For this session, we focus on how to programmatically tell your computer where to locate your experimental files, introducing the concept of [file paths](https://ytakemon.github.io/2019-10-22-R-BCCRC/02-filedir/). We explore how the various operating systems (Linux, MacOS, Windows) specify their respective folders and files, and how to identify where you are currently within the directory. Our goal by the end of this session is to have walked you through how to figure out where an .fcs file of interest is stored, and convey to your computer where you want it copied/moved to, without encountering the common pitfalls. 

<br>
<br>

### Inside an .FCS file

![](https://www.researchgate.net/profile/John-Drakos/publication/5575630/figure/fig1/AS:202978347753476@1425405217571/The-structure-of-FCS-files-The-HEADER-is-a-fixed-size-58-bytes-ASCII-encoded-segment.png)

[**Week 3:**]{.underline} In the course of this session we will slice into an .FCS file and find out what the individual components that make it up are. In the process, we will cover the concepts of main [data structures](http://adv-r.had.co.nz/Data-structures.html) within R (vectors, matrices, data.frames, list) and how to identify what we are working with. Additionally, we will explore how various cytometry softwares store their metadata variables under various keywords that can be useful to know about. 

<br>
<br>

### Introduction to the Tidyverse

![](images/histograms.png){width=75%}

[**Week 4:**]{.underline} Within this session, we explore how the various [tidyverse](https://tidyverse.org/) packages can be utilized to reorganize rows and columns of data in ways that are useful for data analysis. We will primarily work with the MFI expression data we isolated from within the .fcs file in the previous session, identifying and isolating events that meet certain criterias. We introduce the concepts behind ["tidy"](https://vita.had.co.nz/papers/tidy-data.pdf) data and how it can improve our workflows. 

<br>
<br>

### Gating Sets

![](images/GatingSets.png){width=75%}

[**Week 5:**]{.underline} As part of this session, we learn about the two main flow cytometry infrastructure packages in R we will be working with during the course, [flowcore](https://www.bioconductor.org/packages/release/bioc/vignettes/flowCore/inst/doc/HowTo-flowCore.pdf) and [flowWorkspace](https://www.bioconductor.org/packages/release/bioc/vignettes/flowWorkspace/inst/doc/flowWorkspace-Introduction.html). Throughout the session, we will compare how they differ in naming, memory usage, and accessing .fcs file metadata. We additionally explore how to add keywords to their respective metadata for use in filtering specimens of interest from the larger set of .fcs files.   

<br>
<br>

### Visualizing with ggplot2

![](images/StatsIFNg.png)

[**Week 6:**]{.underline} During this session we provide an introduction to the [ggplot2](https://ggplot2.tidyverse.org/) package. We will take the datasets we have collected from the previous sessions and see how in varying in different arguments at the respective plot layers we can produce and customize many different forms of plots, focusing on both cytometry and statistics plots. We close out providing links to [additional helpful resources](https://youtu.be/_indbXPXUw8?si=iZRFHzWvBZg-wu_X) and highlight the [TidyTuesday](https://github.com/rfordatascience/tidytuesday) project. 

<br>
<br>

### Applying Transformations and Compensation

![](images/subsetting.png){width=75%}

[**Week 7:**]{.underline} For this seventh session, we take a closer look at the raw values of the data within our .fcs files, and explore the various ways to [transform](https://docs.flowjo.com/flowjo/graphs-and-gating/gw-transform-overview/) (ie. scale) flow cytometry data in R to better visualize "positive" and "negative populations". In the process, we visualize the differences resulting from applying different transformations commonly used by commercial software. Similarly, we learn how to apply and visualize compensation in context of conventional flow cytometry files. 

<br>
<br>

### It's Raining Functions!

![](https://images2.minutemediacdn.com/image/upload/c_fill,w_720,ar_16:9,f_auto,q_auto,g_auto/shape/cover/sport/raining-monkeys-e3fa8001e4eb47433b1cc58e2017d2b8.png)

[**Week 8:**]{.underline} In the course of this eight session, we tackle one of the harder but most useful concepts to learn for a begginer, namely [functions](https://r4ds.had.co.nz/functions.html). We explore what they are, how their individual arguments work, how they differ from for-loops, and how to create our own to do useful work, reduce the number times code gets copied and pasted. Additionally, some functional programming best practices will be introduced, as well as provide introduction to how to use the walk and map functions from the [purrr](https://purrr.tidyverse.org/) package. 

<br>
<br>

### Downsampling and Concatenation

[**Week 9:**]{.underline} Within this session, we will expand on our growing understanding of GatingSets, functions and fcs file internals to write a script to downsample your fcs files to a desired number (or percentage) of cells for a given cell population. We will additionally learn how to concatenate these downsampled files together, and save them to a new .fcs file in ways that the metadata can be read by commercial software without the scaling being widely thrown off.  

<br>
<br>

### Spectral Signatures

![](images/Signatures.png){width=100%}

[**Week 10:**]{.underline} As part of this session, we will explore how to extract fluorescent signatures from our raw spectral flow cytometry reference controls. Building on prior concepts, we will learn to isolate median signatures from positive and negative gates, and how to derrive and plot normalized signatures. We also introduce [plotly](https://plotly.com/r/) package and it's interactive plotting features, before showcasing various packages attempts at facilitating signature retrieval. 
 
<br>
<br>

### Similarities and Hotspots

![](images/Hotspot.png){width=75%}

[**Week 11:**]{.underline} During this session, we will utilize the spectral signature matrix isolated from raw spectral flow cytometry controls and evaluate different ways of evaluating how similar different fluorescent signatures are to each other.  In the process, we will gain better understanding of the metrics behind similarity (cosine), panel complexity (kappa), and unmixing-dependent spreading (collinearity). 

<br>
<br>

### Retrieving data for Statistics

![](images/TidyData.png){width=33%}

[**Week 12:**]{.underline} Leveraging the increased familiarity working with the various packages this far in the course, in this session we will retrieve summary statistics for the gates within our GatingSet, and programmatically derrive out tidy data.frames for use in statistical analyses typically used by many Immunologist. In the process, we add a couple additional plot types to our ggplot2 arsenal to hold in reserve should Prism prices go up again. 

<br>
<br>

### Unmixing in R

![](Unmixing.png){width=75%}

[**Week 13:**]{.underline} In the course of this session, we will attempt a reach goal of many, namely carry out unmixing of raw .fcs files using the spectral signatures we have isolated from our unmixing controls, and write to new .fcs files. After evaluating the necessary internals, we will explore how various current cytometry R packages have implemented their own unmixing functions, and the various limitations that each approach has encountered.  

<br>
<br>

### Automated Gating

![](images/openCyto.png){width=75%}

[**Week 14:**]{.underline} Within this session, we explore the various automated gating options within [openCyto](https://www.bioconductor.org/packages/release/bioc/vignettes/openCyto/inst/doc/HowToAutoGating.html) and how to setup it's gating templates. We additionally will explore providing additional gate constraints, and various ways to rapidly visually screen and evaluate the outcomes within the context of our own projects.

<br>
<br>

### Cleaning Algorithms

![](images/DegradingAPCFire810Signatures.png){width=75%}

[**Week 15:**]{.underline} In the span of this session, we will directly compare how various Bioconductor data cleanup algorithms (namely [PeacoQC](https://www.bioconductor.org/packages/release/bioc/vignettes/PeacoQC/inst/doc/PeacoQC_Vignette.pdf), [FlowAI](https://www.bioconductor.org/packages/release/bioc/vignettes/flowAI/inst/doc/flowAI.html), [FlowCut](https://www.bioconductor.org/packages/release/bioc/vignettes/flowCut/inst/doc/flowCut.html), and [FlowClean](https://www.bioconductor.org/packages/release/bioc/vignettes/flowClean/inst/doc/flowClean.pdf)) tackle distinguishing and removing bad quality events. We will see how they perform with previously identified good quality and horrific quality .fcs files. We will whether the implemented algorithmic decisions made sense, and how to customize them within our workflows to achieve our own desired goals.

<br>
<br>

### Clustering Algorithms

![](https://docs.flowjo.com/wp-content/uploads/2023/03/image-6-1024x1024.png)

[**Week 16:**]{.underline} As part of this session, we venture away from supervised and semi-supervised analyses to explore unsupervised clustering approaches, namely [FlowSOM](https://onlinelibrary.wiley.com/doi/10.1002/cyto.a.22625) and [Phenograph](https://www.colibri-cytometry.com/post/the-peculiarities-of-phenograph). We will compare outcomes depending markers included, transformations applied, and panel used to gain a greater familiarity with how they work. We wrap up by investigating ways to visualize marker expression of cells ending up in each cluster, and how to backgate them to our manual gates.

<br>
<br>

### Normalization: Batch Effect or Real Biology

![](images/ridgeplots.png){width=75%}

[**Week 17:**]{.underline} During this session, we will dive into evaluating the performance of two commonly used normalization algorithms, [CytoNorm](https://github.com/saeyslab/CytoNorm) and [CyCombine](https://github.com/biosurf/cyCombine). We will utilize our ggplot2 and functional programming toolkits to create a customized workflow to visualize the differences for our respective cell populations before and after normalization, to better evaluate how the respective parameter choices can affect the process.

<br>
<br>

### Dimensionality Visualization

![](images/DimViz.png){width=75%}

[**Week 18:**]{.underline} For this session, we explore how dimensionality visualization algorithms perform [tSNE](https://github.com/lvdmaaten/bhtsne/) and [UMAP](https://github.com/jlmelville/uwot) in R using our raw and unmixed samples. In the process, we will explore how markers included, number of cells, and presence of bad quality events can impact the [final](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011288) visualizations. Finally, we will provide an overview of how to link to Python to additionally run [PaCMAP](https://github.com/YingfanWang/PaCMAP) and [PHATE](https://github.com/KrishnaswamyLab/PHATE) visualizations for use in R.  

<br>
<br>

### Annotating Unsupervised Clusters

![](https://media.geeksforgeeks.org/wp-content/uploads/20230731175958/Bagging-classifier.png)

[**Week 19:**]{.underline} In the course of this session, we explore ways to scale our efficiency in figuring out what an unsupervised cluster of cells may be, by employing several annotation packages. We explore how these work under the hood in their decision making process, and how to link them to reference data from external repositories for additional evaluation. 

<br>
<br>

### The Art of GitHub Diving

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTE3IHi5Y2itTmH60RF81y5b8JnSeeJvTTATA&s)

[**Week 20:**]{.underline} Within this session, we delve into the art of investigating a new-to-you GitHub repository. We discuss the overall structure of R packages stored as source files within GitHub repositories, and how to leverage this knowledge when troubleshooting errors thrown by underdocumented R packages. We discuss how to modify identified functions, evaluate them, and process to submit helpful bug reports back to the original project to help fix the issue.

<br>
<br>

### XML Files All The Way Down

![](https://www.mssqltips.com/wp-content/images-tips/2899_img5.jpg)

[**Week 21:**]{.underline} Breaking news alert, most of the experiment templates and worksheet layouts we work with as cytometrist are .xml files. In this session, we learn some additional coding tools to allow us to work with these types of files to extract useful data. In this session, we test out our new problem solving abilities to retrieve data from SpectroFlo and Diva .xml files to monitor how our core's flow cytometers behaved for various users last week.

<br>
<br>

### Utilizing Bioconductor packages

![](images/Bioconductor.svg){width=75%}

[**Week 22:**]{.underline} Many of the R packages for Flow Cytometry we have utilized in this course were packages from the [Bioconductor](https://www.bioconductor.org/) project. We take a look at what makes Bioconductor packages unique compared to packages found on GitHub and CRAN, explore some of their specific infrastructure types for flow cytometry data, and highlight some useful packages for downstream analysis that we haven't had time to properly explore. 

<br>
<br>

### Building your First R package

![](images/R.png){width=33%}

[**Week 23:**]{.underline} For most of the course, we have been working with R packages that other individuals built and maintained. In this session, we leverage all your hard work from the rest of the course and corral the unwieldly arsenal of functions you wrote into your [first R package](https://r-pkgs.org/introduction.html) for easier use. We will discuss the individual pieces of an R package, the importance of a well-setup namespace file, and how to generate help page manuals to refer future-you back to what your individual function arguments actually do. 

<br>
<br>

### Reproducibility and Replicability

![](https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2F533452a/MediaObjects/41586_2016_BF533452a_Fige_HTML.jpg)

[**Week 24:**]{.underline} As you progressed through the course, you notice we constantly bring up the importance of making both your workspaces and code reproducible and replicable. But what exactly does this mean, and are their ways to do this more efficiently? We explore a couple community-led efforts in the cytometry space and troubleshoot new ways to ease their implementation into our existing workflows. 

<br>
<br>

### Validating algorthmic tools

[**Week 25:**]{.underline} It's always fun learning about new cytometry analysis algorithms at a conference, given we know how much effort goes into creating them. The challenge is how to best evaluate whether their claims hold up over time. While understanding exactly why something involves a boatload of specific knowledge, noticing when the outputs doesn't make sense in your biological context is achievable. We discuss a few show-case examples and work through exploratory data analysis options that would have helped uncover the issues earlier.

<br>
<br>

### Everyone get's a Quarto Website

![](images/3L_V1_Gain_2024.png){width=75%}

[**Week 26:**]{.underline} In this session, we take the knowledge of R code and .qmd documents that we have accumulated over the course, and use them to create our own website using Quarto. We discuss the additional files needed to render the website, how to configure abd update it, and finally set up a new GitHub page to host it for us. 

<br>
<br>

### Open Source Licenses

![](https://cdn.media.amplience.net/i/epammarketplace/Software_Licenses_1?maxW=1200&qlt=80&fmt=jpg&bg=rgb(255,255,255)&v=1365581685114)

[**Week 27:**]{.underline} In this course, we have relied heavily on open-source software to create our own data analysis pipelines, and have some recollection of the various names of licenses each R package was licensed under. But what do all those different names mean in the end? We take a look at the ecosystem of free and open-source licenses, and evaluate what each means for us as users and developers. 

<br>
<br>

### Databases and repositories

![](images/Database.png)

[**Week 28:**]{.underline} While many of us are accustomed with working with large datasets of our own making, increasingly many are working with increasingly large datasets and repositories. How you navigate and manage to retrieve .fcs files and relavent metadata from these repositories can be daunting for the uninnitated. In this section, we take a look at ImmPort (and maybe FlowRepository if it is reachable that day)

<br>
<br>

### Assembling Web Data

[**Week 29:**]{.underline} In this session, we explore the broader topic of web-scraping and APIs in general. We highlight useful packages, and conventions in place to enable retrieval of useful data, while not being responsible for the crash of someone's server. We finish by providing list useful resources for those interested in learning more. 

<br>
<br>

### Future Directions

[**Week 30:**]{.underline} In this final (planned) session, we revisit our challenge problems from the beginning of the course. We also discuss future topics and additional resources that proved helpful. 

<br>
<br>