[
  {
    "objectID": "Schedule.html",
    "href": "Schedule.html",
    "title": "Cytometry in R",
    "section": "",
    "text": "Cytometry in R: A Course for Beginners\nTentative schedule as of November 03, 2025. Please complete the interest form to stay in the loop as we finalize date and times.\n \n\n\nWorkstation Setup\nWeek 1: During this first session, we will ensure that everyone’s computer gets properly setup, as well as start building individual participants familiarity with the software infrastructure that they will be using throughout the rest of the course. Namely, you will need to install R, Rtools, Positron, Quarto, and Git; as well as setup and link to a GitHub account. This session also touches on concepts behind version control and how to install R package from the various repositories (CRAN, Bioconductor, GitHub).\n \n\n\nFile Paths\nWeek 2: For this session, we focus on how to programmatically tell your computer where to locate your experimental files, introducing the concept of file paths. We explore how the various operating systems (Linux, MacOS, Windows) specify their respective folders and files, and how to identify where you are currently within the directory. Our goal by the end of this session is to have walked you through how to figure out where an .fcs file of interest is stored, and convey to your computer where you want it copied/moved to, without encountering the common pitfalls.\n \n\n\nInside an .FCS file\nWeek 3: In the course of this session we will slice into an .FCS file and find out what the individual components that make it up are. In the process, we will cover the concepts of main data structures within R (vectors, matrices, data.frames, list) and how to identify what we are working with. Additionally, we will explore how various cytometry softwares store their metadata variables under various keywords that can be useful to have access to.\n \n\n\nIntroduction to the Tidyverse\n\nWeek 4: Within this session, we explore how the various tidyverse packages can be utilized to reorganize rows and columns of data in ways that are useful for data analysis. We will primarily work with the MFI expression data we isolated from within the .fcs file in the previous session, identifying and isolating events that meet certain criterias. We introduce the concepts behind “tidy” data and how it can improve our workflows.\n \n\n\nGating Sets\n\nWeek 5: As part of this session, we learn about the two main flow cytometry infrastructure packages in R we will be working with during the course, flowcore and flowWorkspace. Throughout the session, we will compare how they differ in naming, memory usage, and accessing .fcs file metadata. We additionally explore how to add keywords to their respective metadata for use in filtering specimens of interest from the larger set of .fcs files.\n \n\n\nVisualizing with ggplot2\n\nWeek 6: During this session we provide an introduction to the ggplot2 package. We will take the datasets we have collected from the previous sessions and see how in varying in different arguments at the respective plot layers we can produce and customize many different forms of plots, focusing on both cytometry and statistics plots. We close out providing links to additional helpful resources and highlight the TidyTuesday project.\n \n\n\nTransformations and compensation\nWeek 7: For this seventh session, we explore how to transform (ie. scale) flow cytometry data in R to more ressemble the plots we encounter using commercial software. We also explore how to apply compensation to conventional flow cytometry files.\n \n\n\nIt’s raining functions\nWeek 8: This eight session takes a detailed walk-through of what is a function, how their arguments work, and how to create your own to do useful work and reduce the number of times code gets copied and pasted. We also cover how to use your own functions with walk and map from the purrr package.\n \n\n\nDownsampling and Concatenation\nWeek 9: This ninth session explores how to downsample your fcs files to a desired number or percentage, and how to concatenate different samples together for use in downstream applications. We also briefly review how to create a new .fcs file.\n \n\n\nSpectral Signatures\n\nWeek 10: In this tenth session we explore extracting fluorescent signatures from our samples, both beads and cells. We build on prior concepts to isolate median of the positive and negative gates. We finally wrap up showcasing various packages that have added ease of life for various steps.\n \n\n\nSimilarities and Hotspots\n\nWeek 11: Utilizing the spectral signatures we retrieved in the prior session, we evaluate spectral similarity using cosine values and panel complexity with kappa. We finally evaluate collinearity by implementing the hotspot matrix.\n \n\n\nRetrieving data for Statistics\n\nWeek 12: Leveraging increasing familiarity with the various packages, we will retrieve the gates from our GatingSet and work on programmatically derriving metrics that are typically used for statistical analysis in cytometry. We will create a couple additional ggplot style plots to add to our arsenal.\n \n\n\nUnmixing in R\nWeek 13: This session goes for a reach goal for many, how to carry out unmixing of raw .fcs files using the spectral signatures we have isolated from our unmixing controls. Once we evaluate the necessary internals, we explore how various cytometry packages have implemented their own individual approaches at tackling this, and various limitations they have encountered.\n \n\n\nAutomated Gating\n\nWeek 14: In this session, we explore openCyto and it’s automated gating templates. We explore various gating implementations and work on learning how to set the gate constraints to work for our own projects. We utilize a cell count dataset for this purpose.\n \n\n\nCleaning Algorithms\n\nWeek 15: In the span of this session, we will directly compare how various Bioconductor data cleanup algorithms (namely PeacoQC, FlowAI, FlowCut, and FlowClean tackle distinguishing and removing bad quality events. We will see how they perform with previously identified good quality and horrific quality .fcs files. We will whether the implemented algorithmic decisions made sense, and how to customize them within our workflows to achieve our own desired goals.\n \n\n\nClustering Algorithms\nWeek 16: We explore unsupervised clustering approaches, primarily FlowSOM, Phenograph, and kmeans. We investigate additional ways of linking these approaches to our manual gating to evaluate the final clusters.\n \n\n\nNormalization vs. Batch Effects\n\nWeek 17: We investigate how to normalize cells using CytoNorm and CyCombine. We evaluate ridge plots and other approaches to carry this out further.\n \n\n\nDimensionality Visualization: Is any of this real?\n\nWeek 18: We perform tSNE and UMAP in R for our raw and unmixed samples. We also walk through the steps of linking to a Python installation in order to run PaCMAP and Phate visualizations.\n \n\n\nAnnotating your unsupervised clusters\nWeek 19: We explore various existing implementations of annotation, that can be modified to label our various clusters and islands. We investigate how these function under the hood in their decision making.\n \n\n\nThe Art of GitHub diving\nWeek 20: While we have been building familiarity with GitHub over the course, there is an art to investigating a new potential package to see if its worthwhile. This session we walk through the main points of how a Github repository is structured, and how to evaluate and use it, submit bug reports, etc.\n \n\n\nXML files all the way down\nWeek 21: The majority of experiment templates and worksheet layouts are actually .xml files. These like other files, can be treated as lines of code, that we can create or edit similar to what we have been doing in the rest of the course. In this session, we test out our new problem solving abilities to retrieve data from SpectroFlo and Diva files to monitor how our cytometers behaved the previous week\n \n\n\nUtilizing Bioconductor packages\nWeek 22: Many of the R packages for Flow Cytometry introduced during this course are also packages available via the Bioconductor project. We take a look at what makes Bioconductor unique compared to packages found on GitHub and CRAN, explore how to merge our workflows with their specific infrastructure, and explore some useful packages for downstream analysis that we haven’t had time to yet explore.\n \n\n\nBuilding your first R package\n\nWeek 23: For most of this course, we have been working using R packages that others have built. In this session, we leverage all the hard work you have already put into the small arsenal of functions and combine them together to create your first R package. We will discuss the individual pieces of an R package, the importance of the namespace file, and how to generate help page manuals to refer back to what your individual function arguments do.\n \n\n\nReproducibility and Replicability\nWeek 24: As you progressed through the course, you notice we constantly bring up the importance of making both your workspaces and code reproducible and replicable. But what exactly does this mean, and are their ways to do this more efficiently? We explore a couple community-led efforts in the cytometry space and troubleshoot new ways to ease their implementation into our existing workflows.\n \n\n\nValidating algorthmic tools\nWeek 25: It’s always fun learning about new cytometry analysis algorithms at a conference, given we know how much effort goes into creating them. The challenge is how to best evaluate whether their claims hold up over time. While understanding exactly why something involves a boatload of specific knowledge, noticing when the outputs doesn’t make sense in your biological context is achievable. We discuss a few show-case examples and work through exploratory data analysis options that would have helped uncover the issues earlier.\n \n\n\nEveryone get’s a Quarto Website\n\nWeek 26: In this session, we take the knowledge of R code and .qmd documents that we have accumulated over the course, and use them to create our own website using Quarto. We discuss the additional files needed to render the website, how to configure abd update it, and finally set up a new GitHub page to host it for us.\n \n\n\nOpen Source Licenses\nWeek 27: In this course, we have relied heavily on open-source software to create our own data analysis pipelines, and have some recollection of the various names of licenses each R package was licensed under. But what do all those different names mean in the end? We take a look at the ecosystem of free and open-source licenses, and evaluate what each means for us as users and developers.\n \n\n\nDatabases and repositories\n\nWeek 28: While many of us are accustomed with working with large datasets of our own making, increasingly many are working with increasingly large datasets and repositories. How you navigate and manage to retrieve .fcs files and relavent metadata from these repositories can be daunting for the uninnitated. In this section, we take a look at ImmPort (and maybe FlowRepository if it is reachable that day)\n \n\n\nGoogle Chrome Inspects the web page\nWeek 29: In this session, we explore the broader topic of web-scraping and APIs in general. We highlight useful packages, and conventions in place to enable retrieval of useful data, while not being responsible for the crash of someone’s server. We finish by providing list useful resources for those interested in learning more.\n \n\n\nFuture Directions\nWeek 30: In this final (planned) session, we revisit our challenge problems from the beginning of the course. We also discuss future topics and additional resources that proved helpful."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "License",
    "section": "",
    "text": "Tentative course outline as of Wednesday October 29, 2025. Click here to see the proposed course content and schedule.\nPlease complete the interest form to stay in the loop as we finalize date and times.\n\nMotivation\n“Cytometry in R” is a weekly mini-course being offered both in-person and online by the Flow Cytometry Shared Resource staff at the University of Maryland Greenebaum Comprehensive Cancer Center. Its primary audience is for those with prior flow cytometry knowledge, who have limited previous experience with the programming language R.\nWhile many cytometry enthusiast express an interest in learning how to carry out flow cytometry analyses in R, they often do not know where to start. Additionally, many of the limited existing resources are focused towards users with intermediate bioinformatic skills, contributing to a greater barrier for entry for those just starting out. Our motivation in offering this mini-course tailored towards beginners is to make the learning journey smoother than the one we ourselves experienced.\n\n\nRationale\nWhile designing the course, we kept the following concepts in mind:\n\nBeginning coders benefit both by having detailed examples that they can initially work through on their own time, as well as less defined problems that through troubleshooting enable the acquisition of the thought-process and skills needed for coding.\nSome topics will take individuals a longer time to fully grasp. Providing a format and resources that enable being able to revisit the material multiple times is incredibly helpful. Likewise, life is busy, and missing a workshop session is highly probable. If this happens, it shouldn’t make or break the ability of the individual to understanding the rest of the course.\nConsistency is key, and being able to apply what you are learning to your own datasets, files, and questions of interest helps achieve this.\n\n\n\nCost\nIs there a cost to participate? No, it’s absolutely free! Is there a catch? Yes, you learn R, and may wind up with strong feelings about flowframes vs. cytoframes. This is also our first year offering this course, so we will sporadically ask you to fill out a feedback form to help us improve.\n\n\nFormat\nEach week, the mini-course will cover a particular topic for an hour. This individual class is offered on multiple days, at different times, both in-person and online. You are invited to attend whichever day best fits your schedule for that week. If life gets busy and you can’t make your regular day, you have an additional four opportunities for that week covering the same topic.\nIn-person, we are tentatively planning on Monday, Wednesday, Friday from 4-5 pm EST in Bressler 7-035. Virtual options are tentatively planned for Tuesday and Thursday via livestream on YouTube and the Cytometry Discord. However, final date and times will be determined on the interest, availability, and timezones of interested particants (please do fill our the interest form).\nEach session starts with 10-15 minutes of Background about the session topic, and it’s relevance to both R and Cytometry. Over the next 30 minutes, participants work through Hands-on examples, using either their own data, or an example dataset that we will provide. Instructors assist where needed and answer questions during this time. The final 10 minutes we reconvene as a group, Share insights and troubleshoot any remaining stickpoints. Finally, we provide links to useful resources for those who want to learn more about the topic, as well as provide two optional take-home problems.\nEach week, we will update the website with the course materials for the week. These will typically consist of the Quarto Markdown document, which is used to explain and run the R code. If you have your own data, you can bring your own data! If you don’t have some, or want to follow along, we will also make available some of our data that you can utilize. All course materials for the given week will be made available online via our course website and course GitHub repository. In our commitment to open-source and open-science, all teaching materials are freely offered under a CC-BY-SA license, while all code examples are offered under the AGPL3-0 copyleft license.\nThe take-home problems are intended to get you to work with your own data on similar problems in a not-so-structured manner. The challenges you encounter in solving them will help foster the problem-solving/debugging/way-of-thinking skills needed to successfully work with code. Both works-and-progress and solved problems can be discussed and submitted on our GitHub repository to the designated take-home folder of the week, where both instructors and others taking the course can provide feedback.\n\n\nComputing Requirements\nFor those attending online, you will need a computer with internet access. Operating system shouldn’t matter, as we will be offering code examples for Linux, Mac and Windows. As with all things flow-cytometry software, a good CPU with multiple cores, more RAM, and greater storage space are generally helpful, but not deal breakers.\nYou will need to be able to install the required software (R, Rtools, Positron, Git, Quarto) as well as intstall and compile R packages from the CRAN and Bioconductor repositories (as well as a few GitHub-based R packages). For those using university or company administered computers, please be aware that you may not have the necessary permissions to install these directly, and may need to reach out to your IT department to help get these initial requirements set up. If you are using your own computer, congratulations, you are your system administrator, and should already have the necessary permissions.\nFor those attending in-person, we have set up a pop-up computer lab in the conference room. For those who arrive early, we have a limited number of second screens with provided mouse and keyboard that you can plug a laptop into via HDMI cable to set up a workstation. For those arriving later, the room has enough space (and electrical plugs) for 20 people, but you will need to balance a laptop on your lap. If you have your own laptop, feel free to bring it. If you don’t have a laptop, the flow core has 6 loaner laptops running Linux that we can let participants use for that session.\n\n\nSchedule\nClick here to see the tentative course content and schedule as of October 29, 2025. Please complete the interest form to stay in the loop as we finalize date and times. Thanks!\n\n\nLicense\nThe course material is licensed under under the Creative Commons Attribution-Share Alike 4.0 International License. The code examples provided in this course are licensed under the GNU AFFERO GENERAL PUBLIC LICENSE (AGPL-3.0)"
  }
]