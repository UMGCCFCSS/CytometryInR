[
  {
    "objectID": "Schedule.html",
    "href": "Schedule.html",
    "title": "Cytometry in R: A Course for Beginners",
    "section": "",
    "text": "Cytometry in R: A Course for Beginners\nTentative schedule as of October 29, 2025. Please complete the interest form to stay in the loop as we finalize date and times.\n\n\nWorkstation Setup\nWeek 1: “Workstation Setup”\nThe main focus of this first session is ensuring everyone’s computer is properly setup, and to start building familiarity with the infrastructure used for the rest of the course.\nParticipants install R, Rtools, Positron, Quarto, and Git; then setup and link a GitHub account. Introduces the concept of version control, and how in combination with Quarto it will be used for submitting optional take-home assignments. Finally, R packages in the flow cytometry context are discussed, including where they can be found (CRAN, Bioconductor, GitHub) and how to install them.\n\n\nFile Paths\nWeek 2: “File Paths”\nThis second session covers file paths, and how they differ between operating systems (Linux, macOS and Windows). The goal is by the end of the session everyone can programmatically locate where there .fcs files are stored, list any other items present in the same folders, and assign alternate storage locations.\n\n\nInside an .FCS file\nWeek 3: “Inside an .FCS file”\nThis third session revolves around breaking open an .FCS file and seeing what are the individual components that make it up. In the process, we cover the concepts of types of data structures within R (vectors, matrices, data.frames, list).\n\n\nIntroduction to the Tidyverse\nWeek 4: “Introduction to the Tidyverse”\nThis fourth session explores how the various Tidyverse packages can be used to rearrange data. We utilize the expression data we isolated from inside our experiment to manipulate data.frames and select for cells that meet certain criteria.\n\n\nGating Sets\nWeek 5: “Gating Sets”\nThis fifth session involves learning about the flow cytometry infrastructure packages, namely FlowCore and flowWorkspace. We explore how they differ in function naming, memory utilization, and metadata retention. We practice adding metadata and filtering on the basis of these conditions.\n\n\nVisualizing with ggplot2\nWeek 6: “Visualizing with ggplot2”\nThis sixth session provides an introduction to the ggplot2 package. We learn about various layer elements that in combination can be used to produce many types of plots. For this session, we visualize data from our fcs files with 1 and 2D histograms, as well as generate a few statistical summary plots. We provide links to additional helpful resources for those interested in learning more\n\n\nTransformations and compensation\nWeek 7: “Transformations and compensation”\nFor this seventh session, we explore how to transform (ie. scale) flow cytometry data in R to more ressemble the plots we encounter using commercial software. We also explore how to apply compensation to conventional flow cytometry files.\n\n\nIt’s raining functions\nWeek 8: “It’s raining functions”\nThis eight session takes a detailed walk-through of what is a function, how their arguments work, and how to create your own to do useful work and reduce the number of times code gets copied and pasted. We also cover how to use your own functions with walk and map from the purrr package.\n\n\nDownsampling and Concatenation\nWeek 9: “Downsampling and Concatenation”\nThis ninth session explores how to downsample your fcs files to a desired number or percentage, and how to concatenate different samples together for use in downstream applications. We also briefly review how to create a new .fcs file.\n\n\nSpectral Signatures\nWeek 10: “Spectral Signatures”\nIn this tenth session we explore extracting fluorescent signatures from our samples, both beads and cells. We build on prior concepts to isolate median of the positive and negative gates. We finally wrap up showcasing various packages that have added ease of life for various steps.\n\n\nSimilarities and Hotspots\nWeek 11: “Similarities and Hotspots”\nUtilizing the spectral signatures we retrieved in the prior session, we evaluate spectral similarity using cosine values and panel complexity with kappa. We finally evaluate collinearity by implementing the hotspot matrix.\n\n\nRetrieving data for Statistics\nWeek 12: “Retrieving data for Statistics”\nLeveraging increasing familiarity with the various packages, we will retrieve the gates from our GatingSet and work on programmatically derriving metrics that are typically used for statistical analysis in cytometry. We will create a couple additional ggplot style plots to add to our arsenal.\n\n\nUnmixing in R\nWeek 13: “Unmixing in R”\nThis session goes for a reach goal for many, how to carry out unmixing of raw .fcs files using the spectral signatures we have isolated from our unmixing controls. Once we evaluate the necessary internals, we explore how various cytometry packages have implemented their own individual approaches at tackling this, and various limitations they have encountered.\n\n\nAutomated Gating\nWeek 14: “Automated Gating”\nIn this session, we explore openCyto and it’s automated gating templates. We explore various gating implementations and work on learning how to set the gate constraints to work for our own projects. We utilize a cell count dataset for this purpose.\n\n\nCleaning Algorithms\nWeek 15: “Cleaning Algorithms”\nWe evaluate the data cleanup algorithms, PeacoQC, FlowAI, FlowCut and FlowClean, and compare the various elements that get targeted for removal. We discuss which of these are worthwhile and how to evaluate whether the algorithmic decisions make sense.\n\n\nClustering Algorithms\nWeek 16: “Clustering Algorithms”\nWe explore unsupervised clustering approaches, primarily FlowSOM, Phenograph, and kmeans. We investigate additional ways of linking these approaches to our manual gating to evaluate the final clusters.\n\n\nNormalization vs. Batch Effects\nWeek 17: “Normalization vs. Batch Effects”\nWe investigate how to normalize cells using CytoNorm and CyCombine. We evaluate ridge plots and other approaches to carry this out further.\n\n\nDimensionality Visualization: Is any of this real?\nWeek 18: “Dimensionality Visualization: Is any of this real?”\nWe perform tSNE and UMAP in R for our raw and unmixed samples. We also walk through the steps of linking to a Python installation in order to run PaCMAP and Phate visualizations.\n\n\nAnnotating your unsupervised clusters\nWeek 19: “Annotating your unsupervised clusters”\nWe explore various existing implementations of annotation, that can be modified to label our various clusters and islands. We investigate how these function under the hood in their decision making.\n\n\nThe Art of GitHub diving\nWeek 20: “The Art of GitHub diving”\nWhile we have been building familiarity with GitHub over the course, there is an art to investigating a new potential package to see if its worthwhile. This session we walk through the main points of how a Github repository is structured, and how to evaluate and use it, submit bug reports, etc.\n\n\nXML files all the way down\nWeek 21: “.XML files all the way down”\nThe majority of experiment templates and worksheet layouts are actually .xml files. These like other files, can be treated as lines of code, that we can create or edit similar to what we have been doing in the rest of the course. In this session, we test out our new problem solving abilities to retrieve data from SpectroFlo and Diva files to monitor how our cytometers behaved the previous week\n\n\nUtilizing Bioconductor packages\nWeek 22: “Utilizing Bioconductor packages”\nMany of the R packages for Flow Cytometry introduced during this course are also packages available via the Bioconductor project. We take a look at what makes Bioconductor unique compared to packages found on GitHub and CRAN, explore how to merge our workflows with their specific infrastructure, and explore some useful packages for downstream analysis that we haven’t had time to yet explore.\n\n\nBuilding your first R package\nWeek 23: “Building your first R package”\nFor most of this course, we have been working using R packages that others have built. In this session, we leverage all the hard work you have already put into the small arsenal of functions and combine them together to create your first R package. We will discuss the individual pieces of an R package, the importance of the namespace file, and how to generate help page manuals to refer back to what your individual function arguments do.\n\n\nReproducibility and Replicability\nWeek 24: “Reproducibility and Replicability”\nAs you progressed through the course, you notice we constantly bring up the importance of making both your workspaces and code reproducible and replicable. But what exactly does this mean, and are their ways to do this more efficiently? We explore a couple community-led efforts in the cytometry space and troubleshoot new ways to ease their implementation into our existing workflows.\n\n\nValidating algorthmic tools\nWeek 25: “Validating algorthmic tools”\nIt’s always fun learning about new cytometry analysis algorithms at a conference, given we know how much effort goes into creating them. The challenge is how to best evaluate whether their claims hold up over time. While understanding exactly why something involves a boatload of specific knowledge, noticing when the outputs doesn’t make sense in your biological context is achievable. We discuss a few show-case examples and work through exploratory data analysis options that would have helped uncover the issues earlier.\n\n\nEveryone get’s a Quarto Website\nWeek 26: “Everyone get’s a Quarto Website”\nIn this session, we take the knowledge of R code and .qmd documents that we have accumulated over the course, and use them to create our own website using Quarto. We discuss the additional files needed to render the website, how to configure abd update it, and finally set up a new GitHub page to host it for us.\n\n\nOpen Source Licenses\nWeek 27: “Open Source Licenses”\nIn this course, we have relied heavily on open-source software to create our own data analysis pipelines, and have some recollection of the various names of licenses each R package was licensed under. But what do all those different names mean in the end? We take a look at the ecosystem of free and open-source licenses, and evaluate what each means for us as users and developers.\n\n\nDatabases and repositories\nWeek 28: “Databases and repositories”\nWhile many of us are accustomed with working with large datasets of our own making, increasingly many are working with increasingly large datasets and repositories. How you navigate and manage to retrieve .fcs files and relavent metadata from these repositories can be daunting for the uninnitated. In this section, we take a look at ImmPort (and maybe FlowRepository if it is reachable that day)\n\n\nGoogle Chrome Inspects the web page\nWeek 29: “Google Chrome Inspects the web page”\nIn this session, we explore the broader topic of web-scraping and APIs in general. We highlight useful packages, and conventions in place to enable retrieval of useful data, while not being responsible for the crash of someone’s server. We finish by providing list useful resources for those interested in learning more.\n\n\nFuture Directions\nWeek 30: “Future Directions”\nIn this final (planned) session, we revisit our challenge problems from the beginning of the course. We also discuss future topics and additional resources that proved helpful."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "License",
    "section": "",
    "text": "Tentative course outline as of Wednesday October 29, 2025. Please complete the interest form to stay in the loop as we finalize date and times.\n\nMotivation\n“Cytometry in R” is a weekly mini-course being offered both in-person and online by the Flow Cytometry Shared Resource staff at the University of Maryland Greenebaum Comprehensive Cancer Center. Its primary audience is for those with prior flow cytometry knowledge, who have limited previous experience with with the programming language R.\nWhile many cytometry enthusiast express an interest in learning how to carry out flow cytometry analyses in R, they often do not know where to start. Additionally, many of the limited existed resources are focused towards users with intermediate bioinformatic skills, contributing to a greater barrier for entry. Our motivation in offering this mini-course tailored towards beginners is to make the learning journey smoother than the one we experienced.\n\n\nRationale\nWhile designing the course, we kept the following concepts in mind:\n\nBeginning coders benefit both by having detailed examples that they can initially work through on their own time, as well as less defined problems that through troubleshooting enable the acquisition of the thought-process and skills needed for coding.\nSome topics will take individuals a longer time to fully grasp. Providing a format and resources that enable being able to revisit the material multiple times is incredibly helpful. Likewise, life is busy, and missing a workshop session is highly probable. If this happens, it shouldn’t make or break the ability of the individual to understanding the rest of the course.\nConsistency is key, and being able to apply what you are learning to your own datasets, files, and questions of interest helps achieve this.\n\n\n\nCost\nIs there a cost to participate? No, it’s absolutely free! Is there a catch? Yes, you learn R, and may wind up with strong feelings about flowframes vs. cytoframes. This is also our first year offering this course, so we will sporadically ask you to fill out a feedback form to help us improve.\n\n\nFormat\nEach week, the mini-course will cover a particular topic for an hour. This individual class is offered on multiple days, at different times, both in-person and online. You are invited to attend whichever day best fits your schedule for that week. If life gets busy and you can’t make your regular day, you have an additional four opportunities for that week covering the same topic.\nIn-person, we are tentatively planning on Monday, Wednesday, Friday from 4-5 pm EST in Bressler 7-035. Virtual options are tentatively planned for Tuesday and Thursday via livestream on YouTube and the Cytometry Discord. However, final date and times will be determined on the interest, availability, and timezones of interested particants (please do fill our the interest form).\nEach session starts with 10-15 minutes of Background about the session topic, and it’s relevance to both R and Cytometry. Over the next 30 minutes, participants work through Hands-on examples, using either their own data, or an example dataset that we will provide. Instructors assist where needed and answer questions during this time. The final 10 minutes we reconvene as a group, Share insights and troubleshoot any remaining stickpoints. Finally, we provide links to useful resources for those who want to learn more about the topic, as well as provide two optional take-home problems.\nEach week, we will update the website with the course materials for the week. These will typically consist of the Quarto Markdown document, which is used to explain and run the R code. If you have your own data, you can bring your own data! If you don’t have some, or want to follow along, we will also make available some of our data that you can utilize. All course materials for the given week will be made available online via our course website and course GitHub repository. In our commitment to open-source and open-science, all teaching materials are freely offered under a CC-BY-SA license, while all code examples are offered under the AGPL3-0 copyleft license.\nThe take-home problems are intended to get you to work with your own data on similar problems in a not-so-structured manner. The challenges you encounter in solving them will help foster the problem-solving/debugging/way-of-thinking skills needed to successfully work with code. Both works-and-progress and solved problems can be discussed and submitted on our GitHub repository to the designated take-home folder of the week, where both instructors and others taking the course can provide feedback.\n\n\nComputing Requirements\nFor those attending online, you will need a computer with internet access. Operating system shouldn’t matter, as we will be offering code examples for Linux, Mac and Windows. As with all things flow-cytometry software, a good CPU with multiple cores, more RAM, and greater storage space are generally helpful, but not deal breakers.\nYou will need to be able to install the required software (R, Rtools, Positron, Git, Quarto) as well as intstall and compile R packages from the CRAN and Bioconductor repositories (as well as a few GitHub-based R packages). For those using university or company administered computers, please be aware that you may not have the necessary permissions to install these directly, and may need to reach out to your IT department to help get these initial requirements set up. If you are using your own computer, congratulations, you are your system administrator, and should already have the necessary permissions.\nFor those attending in-person, we have set up a pop-up computer lab in the conference room. For those who arrive early, we have a limited number of second screens with provided mouse and keyboard that you can plug a laptop into via HDMI cable to set up a workstation. For those arriving later, the room has enough space (and electrical plugs) for 20 people, but you will need to balance a laptop on your lap. If you have your own laptop, feel free to bring it. If you don’t have a laptop, the flow core has 6 loaner laptops running Linux that we can let participants use for that session.\n\n\nSchedule\nClick here to see the tentative course content and schedule as of October 29, 2025. Please complete the interest form to stay in the loop as we finalize date and times. Thanks!\n\n\nLicense\nThe course material is licensed under under the Creative Commons Attribution-Share Alike 4.0 International License. The code examples provided in this course are licensed under the GNU AFFERO GENERAL PUBLIC LICENSE (AGPL-3.0)"
  }
]